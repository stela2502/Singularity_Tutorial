{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bioinformatics focused Apptainer/Singularity Workshop 2024 Introduction to Apptainer Apptainer (formerly known as Singularity) is a powerful containerization tool tailored for scientific and high-performance computing (HPC) environments. Unlike other containerization platforms like Docker, Apptainer is designed with security in mind, allowing users to run containers without needing elevated privileges. This makes it an excellent choice for bioinformaticians working on shared or secure systems. Containers encapsulate software environments, including libraries, dependencies, and the application itself, ensuring reproducibility and ease of deployment. This is especially valuable in bioinformatics, where software dependencies can be complex and challenging to manage. Although Apptainer is available for all major operating systems, the installation process on Windows and Mac is not as straightforward as on a pure Linux system. Therefore, we will run this course using an Apptainer image. This image can be installed on any system that supports Apptainer and allows you to build an image as a regular user. Building Apptainer images for COSMOS-SENSE on open COSMOS For this workshop, we will use the open COSMOS system to build our Apptainer images. To do this, you'll need to download Thinlink and log into open COSMOS at cosmos-dt.lunarc.lu.se. Building an apptainer image does need superuser rights or at least some elevated rights on the system. In other words you can not build an Apptainer image on an HPC platform - even if the platform does support Singulatrity/Apptainer. To fix this we deveoped an Apptainer image that has apptainer installed inside: ImageSmith . This image is based on Apline linux as it produces quite slim images and it is installed as a module on COSMOS. You can load this module with the following command: module load ImageSmith/1.0 However, as responsible bioinformaticians, we will not run the image directly on our frontend systems. Instead, we will execute it on the compute nodes: To do this, copy the following into a file named RunImageSmith.sbatch : #!/bin/bash #SBATCH --ntasks-per-node 1 #SBATCH -N 1 #SBATCH -t 08:00:00 #SBATCH -A lu2024-7-5 #SBATCH -J start_Si #SBATCH -o start_Si.%j.out #SBATCH -e start_Si.%j.err ml ImageSmith/1.0 exit 0 Then start the image with: sbatch RunImageSmith.sbatch After submission, you will receive the PID of the SLURM job. To view the process output, you can use: watch cat <PID> In the output, you will find a web link to access the image. Look for lines similar to: ... [C 2024-09-16 10:33:26.138 ServerApp] To access the server, open this file in a browser: file:///home/stefanl/.local/share/jupyter/runtime/jpserver-2698141-open.html Or copy and paste one of these URLs: http://cn009:9734/lab?token=<token> http://127.0.0.1:9734/lab?token=<token> ... Use one of these URLs to access the image in your browser. In the Jupyter lab web page, you can open a 'Terminal' - that is all we need to build an image. Designing Your Own Apptainer HPC Image When designing your Apptainer HPC image, consider how you want to interact with it: A Server Started in the Image You may want your image to launch a server upon startup, facilitating remote access and interaction. We will not cover that esplicitly here. Command Line Tools Only For those who ONLY rely on command line tools I recommand to create a script that handles the apptainer loading (incluiding all binds and other apptainer options) and make that script available as a command if you load the Lua module. We will not cover this version here, but you can look into my Rustody_image github Repo if you are interested. Interactive Software If you primarily use interactive sessions based on R or Python, I recommend installing JupyterLab. This provides numerous possibilities for interacting with your software like Terminal access, console access to R and Python, and also Jupter notebooks for R and Python. Minimal Configuration For a minimal configuration, we need the following: Python with JupyterLab R R-Jupyter integration This allows for interaction with command line tools as well as interactive usage of Python and R packages. Additional Considerations Unfortunately due to Apptainer internals we are restricted to build the same system as the ImageSmith is based on. So we need to stick with alpine:latest for now. Example Here\u2019s how you can obtain a minimal Apptainer definition file for this setup using ChatGPT: Hi Chatty - can you give me a minimal Apptainer def file that builds this minimal system: What we need in a minimal configuration is therefore: Python with JupyterLab, R, and the R-Jupyter integration. Base it on Apline latest - please. The response is normally lacking quite a bit, but you get the overall structure of the def file for free. If you are critical and look for small things like From alpine:latest you can force Chatty to improve. If nothing else it is a first start. It is helpful to use the free GPT-4o for that. My modified ChatGPT output: # This is an Apptainer definition file for creating a container # based on Alpine Linux with Python, JupyterLab, R, and R-Jupyter integration. Bootstrap: docker From: alpine:latest # Use the latest Alpine Linux image as the base %post # Update the package index and install essential packages apk update # Install build tools and libraries required for Python and R # You must not have comments after the '\\' in the following lines! apk add --no-cache bash \\ build-base \\ zeromq-dev \\ libffi-dev \\ musl-dev \\ openblas-dev \\ R \\ R-dev \\ R-doc \\ python3 \\ py3-pip \\ python3-dev \\ py3-setuptools \\ py3-wheel # Allow pip to modify system-wide packages export PIP_BREAK_SYSTEM_PACKAGES=1 # Install JupyterLab using pip pip3 install --no-cache-dir jupyterlab # Install R packages for Jupyter integration R -e \"install.packages(c('IRkernel', 'IRdisplay'), repos='https://cloud.r-project.org/')\" # Set up IRkernel to make R available as a Jupyter kernel R -e \"IRkernel::installspec(user = FALSE)\" %environment # Ensure /usr/local/bin is in the PATH so JupyterLab can be found export PATH=\"/usr/local/bin:$PATH\" # if you want to install more python packages in the sandbox: export PIP_BREAK_SYSTEM_PACKAGES=1 %runscript # By default, run JupyterLab when the container starts jupyter lab --port 9734 --ip=0.0.0.0 --allow-root --no-browser Let's go back to the ImageSmith to build an image based on this defintion: Create a new directory Jupyter lab allows you to create a folder using the graphical iterface, but you could also use the Terminal: mkdir mkdir Singularity_Workshop cd Singularity_Workshop If you rather want to use the graphical interface: in the upper left corner of the Jupyter lab is an icon list - the third icon creates a new folder. Create the definition file To create the definition file you can cd into the created folder or use Jupyter lab to navigate into that folder. On the command line only the vi editor is installed: vi Singularity_Workshop.def Paste the copied text with the middle mouse button and save & close vi session with :x . Using the Jupyter lab interface you can also create a new file in the folder using the large plus sign benethe the create folder icon. You can then select Other -> Text file in the main window and copy the text into the new file; save it as \"Singularity_Workshop.def\". Build a Apptainer sandbox To build that sandbox for manual modification we can run this command: apptainer build --sandbox Singularity_Workshop Singularity_Workshop.def If this breaks with your own version of the def file I recommand to create a new Minimal.def text file with all lines of the %post removed: Bootstrap: docker From: alpine:latest # Use the latest Alpine Linux image as the base %post %environment # Ensure /usr/local/bin is in the PATH so JupyterLab can be found export PATH=\"/usr/local/bin:$PATH\" # if you want to install more python packages in the sandbox: export PIP_BREAK_SYSTEM_PACKAGES=1 %runscript # By default, run JupyterLab when the container starts jupyter lab --port 9734 --ip=0.0.0.0 --allow-root --no-browser You should keep the %environment and the %runscript as this will allow you to (1) install your packages as the install script will install them pater on and (2) test if the manually modified sandbox can start the jupyter lab as expected in the end. From that mminaiml def file you can build a MINIMAL sandbox and install your packages manuall - hammering out the issues of your %post section in one go: apptainer build --sandbox Singularity_Workshop MINAIMAL.def apptainer shell --writable Singularity_Workshop Or - assuming that the Singularity_Workshop sandbox was built correctly we now can use that sandbox to install the packages that we need for our daily work: apptainer shell --writable Singularity_Workshop Install the software you need and do not forget to add all working install steps to the def file, too. This way all later builds will already have your modifications in it! Finally we build the image with: apptainer build Singularity_Workshop.sif Singularity_Workshop Or after you have added all manual steps into the def file: apptainer build Singularity_Workshop.sif Singularity_Workshop.def That is the bare bone of image creation. But how do we add this Apptainer image as a COSMOS-SENSE module ?","title":"Build an Apptainer image"},{"location":"#bioinformatics-focused-apptainersingularity-workshop-2024","text":"","title":"Bioinformatics focused Apptainer/Singularity Workshop 2024"},{"location":"#introduction-to-apptainer","text":"Apptainer (formerly known as Singularity) is a powerful containerization tool tailored for scientific and high-performance computing (HPC) environments. Unlike other containerization platforms like Docker, Apptainer is designed with security in mind, allowing users to run containers without needing elevated privileges. This makes it an excellent choice for bioinformaticians working on shared or secure systems. Containers encapsulate software environments, including libraries, dependencies, and the application itself, ensuring reproducibility and ease of deployment. This is especially valuable in bioinformatics, where software dependencies can be complex and challenging to manage. Although Apptainer is available for all major operating systems, the installation process on Windows and Mac is not as straightforward as on a pure Linux system. Therefore, we will run this course using an Apptainer image. This image can be installed on any system that supports Apptainer and allows you to build an image as a regular user.","title":"Introduction to Apptainer"},{"location":"#building-apptainer-images-for-cosmos-sense-on-open-cosmos","text":"For this workshop, we will use the open COSMOS system to build our Apptainer images. To do this, you'll need to download Thinlink and log into open COSMOS at cosmos-dt.lunarc.lu.se. Building an apptainer image does need superuser rights or at least some elevated rights on the system. In other words you can not build an Apptainer image on an HPC platform - even if the platform does support Singulatrity/Apptainer. To fix this we deveoped an Apptainer image that has apptainer installed inside: ImageSmith . This image is based on Apline linux as it produces quite slim images and it is installed as a module on COSMOS. You can load this module with the following command: module load ImageSmith/1.0 However, as responsible bioinformaticians, we will not run the image directly on our frontend systems. Instead, we will execute it on the compute nodes: To do this, copy the following into a file named RunImageSmith.sbatch : #!/bin/bash #SBATCH --ntasks-per-node 1 #SBATCH -N 1 #SBATCH -t 08:00:00 #SBATCH -A lu2024-7-5 #SBATCH -J start_Si #SBATCH -o start_Si.%j.out #SBATCH -e start_Si.%j.err ml ImageSmith/1.0 exit 0 Then start the image with: sbatch RunImageSmith.sbatch After submission, you will receive the PID of the SLURM job. To view the process output, you can use: watch cat <PID> In the output, you will find a web link to access the image. Look for lines similar to: ... [C 2024-09-16 10:33:26.138 ServerApp] To access the server, open this file in a browser: file:///home/stefanl/.local/share/jupyter/runtime/jpserver-2698141-open.html Or copy and paste one of these URLs: http://cn009:9734/lab?token=<token> http://127.0.0.1:9734/lab?token=<token> ... Use one of these URLs to access the image in your browser. In the Jupyter lab web page, you can open a 'Terminal' - that is all we need to build an image.","title":"Building Apptainer images for COSMOS-SENSE on open COSMOS"},{"location":"#designing-your-own-apptainer-hpc-image","text":"When designing your Apptainer HPC image, consider how you want to interact with it: A Server Started in the Image You may want your image to launch a server upon startup, facilitating remote access and interaction. We will not cover that esplicitly here. Command Line Tools Only For those who ONLY rely on command line tools I recommand to create a script that handles the apptainer loading (incluiding all binds and other apptainer options) and make that script available as a command if you load the Lua module. We will not cover this version here, but you can look into my Rustody_image github Repo if you are interested. Interactive Software If you primarily use interactive sessions based on R or Python, I recommend installing JupyterLab. This provides numerous possibilities for interacting with your software like Terminal access, console access to R and Python, and also Jupter notebooks for R and Python.","title":"Designing Your Own Apptainer HPC Image"},{"location":"#minimal-configuration","text":"For a minimal configuration, we need the following: Python with JupyterLab R R-Jupyter integration This allows for interaction with command line tools as well as interactive usage of Python and R packages.","title":"Minimal Configuration"},{"location":"#additional-considerations","text":"Unfortunately due to Apptainer internals we are restricted to build the same system as the ImageSmith is based on. So we need to stick with alpine:latest for now.","title":"Additional Considerations"},{"location":"#example","text":"Here\u2019s how you can obtain a minimal Apptainer definition file for this setup using ChatGPT: Hi Chatty - can you give me a minimal Apptainer def file that builds this minimal system: What we need in a minimal configuration is therefore: Python with JupyterLab, R, and the R-Jupyter integration. Base it on Apline latest - please. The response is normally lacking quite a bit, but you get the overall structure of the def file for free. If you are critical and look for small things like From alpine:latest you can force Chatty to improve. If nothing else it is a first start. It is helpful to use the free GPT-4o for that. My modified ChatGPT output: # This is an Apptainer definition file for creating a container # based on Alpine Linux with Python, JupyterLab, R, and R-Jupyter integration. Bootstrap: docker From: alpine:latest # Use the latest Alpine Linux image as the base %post # Update the package index and install essential packages apk update # Install build tools and libraries required for Python and R # You must not have comments after the '\\' in the following lines! apk add --no-cache bash \\ build-base \\ zeromq-dev \\ libffi-dev \\ musl-dev \\ openblas-dev \\ R \\ R-dev \\ R-doc \\ python3 \\ py3-pip \\ python3-dev \\ py3-setuptools \\ py3-wheel # Allow pip to modify system-wide packages export PIP_BREAK_SYSTEM_PACKAGES=1 # Install JupyterLab using pip pip3 install --no-cache-dir jupyterlab # Install R packages for Jupyter integration R -e \"install.packages(c('IRkernel', 'IRdisplay'), repos='https://cloud.r-project.org/')\" # Set up IRkernel to make R available as a Jupyter kernel R -e \"IRkernel::installspec(user = FALSE)\" %environment # Ensure /usr/local/bin is in the PATH so JupyterLab can be found export PATH=\"/usr/local/bin:$PATH\" # if you want to install more python packages in the sandbox: export PIP_BREAK_SYSTEM_PACKAGES=1 %runscript # By default, run JupyterLab when the container starts jupyter lab --port 9734 --ip=0.0.0.0 --allow-root --no-browser Let's go back to the ImageSmith to build an image based on this defintion:","title":"Example"},{"location":"#create-a-new-directory","text":"Jupyter lab allows you to create a folder using the graphical iterface, but you could also use the Terminal: mkdir mkdir Singularity_Workshop cd Singularity_Workshop If you rather want to use the graphical interface: in the upper left corner of the Jupyter lab is an icon list - the third icon creates a new folder.","title":"Create a new directory"},{"location":"#create-the-definition-file","text":"To create the definition file you can cd into the created folder or use Jupyter lab to navigate into that folder. On the command line only the vi editor is installed: vi Singularity_Workshop.def Paste the copied text with the middle mouse button and save & close vi session with :x . Using the Jupyter lab interface you can also create a new file in the folder using the large plus sign benethe the create folder icon. You can then select Other -> Text file in the main window and copy the text into the new file; save it as \"Singularity_Workshop.def\".","title":"Create the definition file"},{"location":"#build-a-apptainer-sandbox","text":"To build that sandbox for manual modification we can run this command: apptainer build --sandbox Singularity_Workshop Singularity_Workshop.def If this breaks with your own version of the def file I recommand to create a new Minimal.def text file with all lines of the %post removed: Bootstrap: docker From: alpine:latest # Use the latest Alpine Linux image as the base %post %environment # Ensure /usr/local/bin is in the PATH so JupyterLab can be found export PATH=\"/usr/local/bin:$PATH\" # if you want to install more python packages in the sandbox: export PIP_BREAK_SYSTEM_PACKAGES=1 %runscript # By default, run JupyterLab when the container starts jupyter lab --port 9734 --ip=0.0.0.0 --allow-root --no-browser You should keep the %environment and the %runscript as this will allow you to (1) install your packages as the install script will install them pater on and (2) test if the manually modified sandbox can start the jupyter lab as expected in the end. From that mminaiml def file you can build a MINIMAL sandbox and install your packages manuall - hammering out the issues of your %post section in one go: apptainer build --sandbox Singularity_Workshop MINAIMAL.def apptainer shell --writable Singularity_Workshop Or - assuming that the Singularity_Workshop sandbox was built correctly we now can use that sandbox to install the packages that we need for our daily work: apptainer shell --writable Singularity_Workshop Install the software you need and do not forget to add all working install steps to the def file, too. This way all later builds will already have your modifications in it! Finally we build the image with: apptainer build Singularity_Workshop.sif Singularity_Workshop Or after you have added all manual steps into the def file: apptainer build Singularity_Workshop.sif Singularity_Workshop.def That is the bare bone of image creation. But how do we add this Apptainer image as a COSMOS-SENSE module ?","title":"Build a Apptainer sandbox"},{"location":"AMakefileBasedApproach/","text":"A Makefile-based approach to build and maintain an Apptainer image My plan for this task is to create a command that streamlines the development of an Apptainer image, much like how cargo new <package_name> --lib sets up a new Rust library project. The goal is to establish a structure where both the Apptainer build and deployment processes are automated and easily configurable. By doing so, you can quickly update the version or even the name of your package without needing to rewrite the build configuration each time. The main focus should be on creating a robust definition file, with the initial setup of the Lua model definition and other components being a one-time effort. The ImageSmith has my implementation of that idea installed as ascript: /opt/ImageSmith/create_new_image_builder.sh <new_directory_name> This will create a folder and populate it with a Makefile, a default definition file and three scripts; shell.sh , run.sh and generate_module.sh . Makefile Options Explained all : This is the default target that runs when you simply type make. It sequentially executes the clean, restart, build, and deploy targets. This option is a convenient way to manage the entire process in one go. restart : This target handles the sandbox environment, which is used to create the image. If the sandbox directory $(SANDBOX_DIR) already exists, it replaces it's contents; otherwise, it creates a new one. The sandbox is essentially a writable container that you can modify before building the final image. Key command: sudo apptainer build --sandbox $(SANDBOX_DIR) $(DEFINITION_FILE) build : This target builds the final Singularity image $(IMAGE_NAME) from the sandbox. The image is based on the sandbox. This is in theory not necessary if you update your definition file. I recommend to add all changes you apply to the sandbox to the definition file, too! But I do not always adhere to that philosophy... Key command: sudo apptainer build $(IMAGE_NAME) $(SANDBOX_DIR) deploy : This target copies the final image to the specified deployment directory $(DEPLOY_DIR) and creates the Lua defintion file based on the informations in the Makefile and the Lua outline in the generate_module.sh script. This is useful for moving the image to a location where it can be accessed and used by others. Key command: cp $(IMAGE_NAME) $(DEPLOY_DIR) clean : This target removes the sandbox directory and the image file. It's useful for cleaning up your workspace if you need to start fresh or if you're done with the current build. Key command: rm -rf $(SANDBOX_DIR) $(IMAGE_NAME How to Use This Package After creating a new Apptainer image project, all scripts and the Makefile will be updated with your project name. To build a standard Bioinformatics Apptainer image, run: make -C <new_directory_name> This will create the sandbox, build the image, and deploy the module to a path in your home folder. The deploy step is tailored to my development environment where I mount the COSMOS-SENS shared folder in ~/sens05_shared/. When you also do that you can deploy the image directly to COMSOS_SENS. At the moment this will create the whole (local) folder and place the module there. This module will work as is if you copy it to COSMOS-SENS by hand. Test the module on open COSMOS The first test should be if you can load it directly using apptainer: apptainer run <your new package>_v1.0.sif But do not forget to run that on the compute nodes, too. You can also test the function of the Lua module on open COSMOS, but for that you need to adjust the path the Lua module expects the image: Open the created Lua file at ~/sens05_shared/common/modules/<SANDBOX_DIR>/<VERSION>.lua . You need to change the line local base = pathJoin(\"/scale/gr01/shared/common/software/<SANDBOX_DIR>/<VERSION>\") to home=os.getenv( \"HOME\" ) local base = pathJoin(home,\"/sens05_shared/common/software/<SANDBOX_DIR>/<VERSION>\") Keep the project specific <SANDBOX_DIR>/<VERSION> . Afterwards you can register your personal modules / software folder pair as module paths like that: module use ~/sens05_shared/common/modules/ Afterwads you can 'run' your new Apptainer image using module load <SANDBOX_DIR>/<VERSION> Please do not forget to run the image on the compute nodes again: #!/bin/bash #SBATCH --ntasks-per-node 1 #SBATCH -N 1 #SBATCH -t 08:00:00 #SBATCH -A lu2024-7-5 #SBATCH -J start_Si #SBATCH -o start_Si.%j.out #SBATCH -e start_Si.%j.err ml <SANDBOX_DIR>/<VERSION> exit 0 If you have modified the Lua definition file and now want to copy the image to COSMOS-SENS the easiest is to remove the ~/sens01_shared/common folder and re-deploy the module: make deploy Thank you for participating in this workshop! I hope you found it useful, and I appreciate your involvement.","title":"A Makefile based approach"},{"location":"AMakefileBasedApproach/#a-makefile-based-approach-to-build-and-maintain-an-apptainer-image","text":"My plan for this task is to create a command that streamlines the development of an Apptainer image, much like how cargo new <package_name> --lib sets up a new Rust library project. The goal is to establish a structure where both the Apptainer build and deployment processes are automated and easily configurable. By doing so, you can quickly update the version or even the name of your package without needing to rewrite the build configuration each time. The main focus should be on creating a robust definition file, with the initial setup of the Lua model definition and other components being a one-time effort. The ImageSmith has my implementation of that idea installed as ascript: /opt/ImageSmith/create_new_image_builder.sh <new_directory_name> This will create a folder and populate it with a Makefile, a default definition file and three scripts; shell.sh , run.sh and generate_module.sh .","title":"A Makefile-based approach to build and maintain an Apptainer image"},{"location":"AMakefileBasedApproach/#makefile-options-explained","text":"all : This is the default target that runs when you simply type make. It sequentially executes the clean, restart, build, and deploy targets. This option is a convenient way to manage the entire process in one go. restart : This target handles the sandbox environment, which is used to create the image. If the sandbox directory $(SANDBOX_DIR) already exists, it replaces it's contents; otherwise, it creates a new one. The sandbox is essentially a writable container that you can modify before building the final image. Key command: sudo apptainer build --sandbox $(SANDBOX_DIR) $(DEFINITION_FILE) build : This target builds the final Singularity image $(IMAGE_NAME) from the sandbox. The image is based on the sandbox. This is in theory not necessary if you update your definition file. I recommend to add all changes you apply to the sandbox to the definition file, too! But I do not always adhere to that philosophy... Key command: sudo apptainer build $(IMAGE_NAME) $(SANDBOX_DIR) deploy : This target copies the final image to the specified deployment directory $(DEPLOY_DIR) and creates the Lua defintion file based on the informations in the Makefile and the Lua outline in the generate_module.sh script. This is useful for moving the image to a location where it can be accessed and used by others. Key command: cp $(IMAGE_NAME) $(DEPLOY_DIR) clean : This target removes the sandbox directory and the image file. It's useful for cleaning up your workspace if you need to start fresh or if you're done with the current build. Key command: rm -rf $(SANDBOX_DIR) $(IMAGE_NAME","title":"Makefile Options Explained"},{"location":"AMakefileBasedApproach/#how-to-use-this-package","text":"After creating a new Apptainer image project, all scripts and the Makefile will be updated with your project name. To build a standard Bioinformatics Apptainer image, run: make -C <new_directory_name> This will create the sandbox, build the image, and deploy the module to a path in your home folder. The deploy step is tailored to my development environment where I mount the COSMOS-SENS shared folder in ~/sens05_shared/. When you also do that you can deploy the image directly to COMSOS_SENS. At the moment this will create the whole (local) folder and place the module there. This module will work as is if you copy it to COSMOS-SENS by hand.","title":"How to Use This Package"},{"location":"AMakefileBasedApproach/#test-the-module-on-open-cosmos","text":"The first test should be if you can load it directly using apptainer: apptainer run <your new package>_v1.0.sif But do not forget to run that on the compute nodes, too. You can also test the function of the Lua module on open COSMOS, but for that you need to adjust the path the Lua module expects the image: Open the created Lua file at ~/sens05_shared/common/modules/<SANDBOX_DIR>/<VERSION>.lua . You need to change the line local base = pathJoin(\"/scale/gr01/shared/common/software/<SANDBOX_DIR>/<VERSION>\") to home=os.getenv( \"HOME\" ) local base = pathJoin(home,\"/sens05_shared/common/software/<SANDBOX_DIR>/<VERSION>\") Keep the project specific <SANDBOX_DIR>/<VERSION> . Afterwards you can register your personal modules / software folder pair as module paths like that: module use ~/sens05_shared/common/modules/ Afterwads you can 'run' your new Apptainer image using module load <SANDBOX_DIR>/<VERSION> Please do not forget to run the image on the compute nodes again: #!/bin/bash #SBATCH --ntasks-per-node 1 #SBATCH -N 1 #SBATCH -t 08:00:00 #SBATCH -A lu2024-7-5 #SBATCH -J start_Si #SBATCH -o start_Si.%j.out #SBATCH -e start_Si.%j.err ml <SANDBOX_DIR>/<VERSION> exit 0 If you have modified the Lua definition file and now want to copy the image to COSMOS-SENS the easiest is to remove the ~/sens01_shared/common folder and re-deploy the module: make deploy Thank you for participating in this workshop! I hope you found it useful, and I appreciate your involvement.","title":"Test the module on open COSMOS"},{"location":"HowToSetUpAModule/","text":"How to set up an Apptainer image as a COSMOS-SENSE module We have a shared folder in COSMOS-SENS /scale/gr01/shared/common/ where we have set up a modules and software folder. The modules installed there can be loaded into the module system by issuing: module use /scale/gr01/shared/common/modules Afterwards all modules that were created by us are available using the normal module spider module_name module load module_name/version To register a module you need to create the same folder in both the modules and software folder. Software will be installed into a software/<version>/ directory whereas the Lua definition of the software will reside in the file modules/<version>.lua . I am no master of modules and can only help you a litlle here. A typical module definition file can look like that: help([[This module is an example Singularity Image prowiding a 'naked' Python Jupyter Lab interface to both Python and R ]]) local version = 1.0 local base = pathJoin(\"/scale/gr01/shared/common/software/Singularity_Workshop/1.0\") -- this happens at load execute{cmd=\"singularity run -B/scale,/sw \".. base.. \"/Singularity_Workshop_v1.0.sif\", modeA={\"load\"} } -- this happens at unload -- nothing here whatis(\"Name : Singularity_Workshop singularity image\") whatis(\"Version : Singularity_Workshop 1.0) whatis(\"Category : Image\") whatis(\"Description : Singularity image providing Python and R and a jupyter lab\") whatis(\"Installed on : 17.09.2024 \") whatis(\"Modified on : --- \") whatis(\"Installed by : Stefan Lang\") family(\"images\") -- these I normally let in here for help if I need something else -- Change Module Path --local mroot = os.getenv(\"MODULEPATH_ROOT\") --local mdir = pathJoin(mroot,\"Compiler/anaconda\",version) --prepend_path(\"MODULEPATH\",mdir) -- This module Lua file already specifies where the image should be placed: local base = pathJoin(\"/scale/gr01/shared/common/software/Singularity_Workshop/1.0\") execute{cmd=\"singularity run -B/scale,/sw \".. base.. \"/Singularity_Workshop_v1.0.sif\", modeA={\"load\"} } We need to copy the image to /scale/gr01/shared/common/software/Singularity_Workshop/1.0/Singularity_Workshop_v1.0.sif . Of cause that module name will not be available for all of you due to user access rights restrictions on our shared folders. In other words, you will need to rename your module. I often forget to change the module name or version in one or more places (an apptainer call or anywhere in the module). To simplify this whole process, I have transitioned from executing commands in the terminal to using a Makefile based approach .","title":"Set up a Lua module"},{"location":"HowToSetUpAModule/#how-to-set-up-an-apptainer-image-as-a-cosmos-sense-module","text":"We have a shared folder in COSMOS-SENS /scale/gr01/shared/common/ where we have set up a modules and software folder. The modules installed there can be loaded into the module system by issuing: module use /scale/gr01/shared/common/modules Afterwards all modules that were created by us are available using the normal module spider module_name module load module_name/version To register a module you need to create the same folder in both the modules and software folder. Software will be installed into a software/<version>/ directory whereas the Lua definition of the software will reside in the file modules/<version>.lua . I am no master of modules and can only help you a litlle here. A typical module definition file can look like that: help([[This module is an example Singularity Image prowiding a 'naked' Python Jupyter Lab interface to both Python and R ]]) local version = 1.0 local base = pathJoin(\"/scale/gr01/shared/common/software/Singularity_Workshop/1.0\") -- this happens at load execute{cmd=\"singularity run -B/scale,/sw \".. base.. \"/Singularity_Workshop_v1.0.sif\", modeA={\"load\"} } -- this happens at unload -- nothing here whatis(\"Name : Singularity_Workshop singularity image\") whatis(\"Version : Singularity_Workshop 1.0) whatis(\"Category : Image\") whatis(\"Description : Singularity image providing Python and R and a jupyter lab\") whatis(\"Installed on : 17.09.2024 \") whatis(\"Modified on : --- \") whatis(\"Installed by : Stefan Lang\") family(\"images\") -- these I normally let in here for help if I need something else -- Change Module Path --local mroot = os.getenv(\"MODULEPATH_ROOT\") --local mdir = pathJoin(mroot,\"Compiler/anaconda\",version) --prepend_path(\"MODULEPATH\",mdir) -- This module Lua file already specifies where the image should be placed: local base = pathJoin(\"/scale/gr01/shared/common/software/Singularity_Workshop/1.0\") execute{cmd=\"singularity run -B/scale,/sw \".. base.. \"/Singularity_Workshop_v1.0.sif\", modeA={\"load\"} } We need to copy the image to /scale/gr01/shared/common/software/Singularity_Workshop/1.0/Singularity_Workshop_v1.0.sif . Of cause that module name will not be available for all of you due to user access rights restrictions on our shared folders. In other words, you will need to rename your module. I often forget to change the module name or version in one or more places (an apptainer call or anywhere in the module). To simplify this whole process, I have transitioned from executing commands in the terminal to using a Makefile based approach .","title":"How to set up an Apptainer image as a COSMOS-SENSE module"},{"location":"InDetailDefFile/","text":"A simple Apptainer def file explained (by ChatGPT): # Apptainer definition file for Python, JupyterLab, and R BootStrap: docker From: ubuntu:latest %post # Update and install basic dependencies apt-get update && apt-get install -y \\ wget \\ curl \\ build-essential \\ libssl-dev \\ libcurl4-openssl-dev \\ libxml2-dev \\ software-properties-common \\ dirmngr \\ gnupg2 \\ locales # Set locale to UTF-8 locale-gen en_US.UTF-8 update-locale LANG=en_US.UTF-8 export PYTHONNOUSERSITE=\"true\" # Install Python and JupyterLab apt-get install -y python3 python3-pip python3-dev pip3 install --upgrade pip pip3 install jupyterlab # Install R and dependencies apt-get install -y r-base r-base-dev # Install R-Jupyter integration (IRKernel) R -e \"install.packages('IRkernel', repos='https://cloud.r-project.org/')\" R -e \"IRkernel::installspec(user = FALSE)\" # Register R kernel with Jupyter # Clean up apt-get clean rm -rf /var/lib/apt/lists/* %environment # Set environment variables export LC_ALL=C.UTF-8 export LANG=C.UTF-8 export PYTHONNOUSERSITE=\"true\" %runscript # Default command to run when the container starts jupyter lab --no-browser --ip=0.0.0.0 --allow-root %labels Maintainer ChatGPT Version 1.0 %help This Apptainer container includes: - Python with JupyterLab - R with Jupyter integration (IRKernel) - Based on Ubuntu latest Step-by-Step Breakdown: 1. BootStrap and From Directives: BootStrap: docker From: ubuntu:latest BootStrap: docker: This tells Apptainer to use a Docker image as the base for building the container. Docker images are convenient because they\u2019re lightweight and pre-built for many common environments. From: ubuntu: Specifies that the base image will be the latest version of Ubuntu. Ubuntu is a popular, stable Linux distribution with a vast ecosystem of packages and community support. Using latest ensures you\u2019re always working with the most up-to-date version. 2. %post Section: This section runs a series of commands to set up the environment inside the container. Everything in the %post section is executed after the base image is pulled. %post a) System Update and Install Dependencies: apt-get update && apt-get install -y \\ wget \\ curl \\ build-essential \\ libssl-dev \\ libcurl4-openssl-dev \\ libxml2-dev \\ software-properties-common \\ dirmngr \\ gnupg2 \\ locales apt-get update: Updates the package list for the Ubuntu system so that the latest versions of software can be installed. apt-get install: Installs the specified packages. wget and curl: Tools to download files and data over HTTP/FTP. build-essential: A meta-package that installs essential tools for compiling and building software (like gcc, make). libssl-dev, libcurl4-openssl-dev, libxml2-dev: Development libraries often required for installing Python/R packages (particularly those that involve networking, encryption, or XML parsing). software-properties-common: Enables the management of software repositories. dirmngr, gnupg2: Tools needed to manage and work with GPG keys (used to sign and verify software sources). locales: Allows the configuration of system language settings. b) Set Locale: locale-gen en_US.UTF-8 update-locale LANG=en_US.UTF-8 locale-gen en_US.UTF-8: Generates the en_US.UTF-8 locale, which is a widely used UTF-8 encoded character set. It ensures that the environment supports a full range of characters, which is important for Python, R, and JupyterLab. update-locale: Applies the locale changes by setting the LANG environment variable. c) Install Python, Pip, and JupyterLab: apt-get install -y python3 python3-pip python3-dev pip3 install --upgrade pip pip3 install jupyterlab apt-get install python3, python3-pip, python3-dev: Installs Python 3 and its development tools (python3-dev), which are required for building Python modules and extensions. pip3 install --upgrade pip: Upgrades pip (Python's package manager) to the latest version to ensure that newer Python packages can be installed. pip3 install jupyterlab: Installs JupyterLab, a web-based interactive development environment for notebooks, code, and data. d) Install R and R Development Tools: apt-get install -y r-base r-base-dev These are all ubuntu system packages - if you want another version of R you need to change this. r-base: Installs the core R environment. r-base-dev: Includes additional tools needed to compile R packages from source. e) Install R-Jupyter Integration (IRKernel): R -e \"install.packages('IRkernel', repos='https://cloud.r-project.org 2. %environment Section: # Set environment variables export LC_ALL=C.UTF-8 export LANG=C.UTF-8 export PYTHONNOUSERSITE=\"true\" This part is one of the benefits of using ChatGPT - in all my definition files before that I have not set these variables and was rewarded by warnings messages at every step. LC_ALL and LANG : Setting these environment variables ensures that the container's environment adheres to the specified locale settings when it's running. PYTHONNOUSERSITE=\"true\" : This env variable forces Python to install packages in the system's library path and not your personly Python library. 3. %runscript jupyter lab --no-browser --ip=0.0.0.0 --allow-root This will start the jupyter web browser and write the connection details into the stdout of the slurm job. 4. %labels Section and 5. %help Section Both of these sections are not necessary for the image to build, but would help us a lot if you would still maintain them! The %labels section can be queried like that: apptainer inspect <your_image>.sif and the %help section like that: apptainer run <our_image>.sif You can see how a well maintained apptainer image can help both you and also us later on - not claiming that I have maintained my images well...","title":"A simple Apptainer def file explained (by ChatGPT):"},{"location":"InDetailDefFile/#a-simple-apptainer-def-file-explained-by-chatgpt","text":"# Apptainer definition file for Python, JupyterLab, and R BootStrap: docker From: ubuntu:latest %post # Update and install basic dependencies apt-get update && apt-get install -y \\ wget \\ curl \\ build-essential \\ libssl-dev \\ libcurl4-openssl-dev \\ libxml2-dev \\ software-properties-common \\ dirmngr \\ gnupg2 \\ locales # Set locale to UTF-8 locale-gen en_US.UTF-8 update-locale LANG=en_US.UTF-8 export PYTHONNOUSERSITE=\"true\" # Install Python and JupyterLab apt-get install -y python3 python3-pip python3-dev pip3 install --upgrade pip pip3 install jupyterlab # Install R and dependencies apt-get install -y r-base r-base-dev # Install R-Jupyter integration (IRKernel) R -e \"install.packages('IRkernel', repos='https://cloud.r-project.org/')\" R -e \"IRkernel::installspec(user = FALSE)\" # Register R kernel with Jupyter # Clean up apt-get clean rm -rf /var/lib/apt/lists/* %environment # Set environment variables export LC_ALL=C.UTF-8 export LANG=C.UTF-8 export PYTHONNOUSERSITE=\"true\" %runscript # Default command to run when the container starts jupyter lab --no-browser --ip=0.0.0.0 --allow-root %labels Maintainer ChatGPT Version 1.0 %help This Apptainer container includes: - Python with JupyterLab - R with Jupyter integration (IRKernel) - Based on Ubuntu latest","title":"A simple Apptainer def file explained (by ChatGPT):"},{"location":"InDetailDefFile/#step-by-step-breakdown","text":"","title":"Step-by-Step Breakdown:"},{"location":"InDetailDefFile/#1-bootstrap-and-from-directives","text":"BootStrap: docker From: ubuntu:latest BootStrap: docker: This tells Apptainer to use a Docker image as the base for building the container. Docker images are convenient because they\u2019re lightweight and pre-built for many common environments. From: ubuntu: Specifies that the base image will be the latest version of Ubuntu. Ubuntu is a popular, stable Linux distribution with a vast ecosystem of packages and community support. Using latest ensures you\u2019re always working with the most up-to-date version.","title":"1. BootStrap and From Directives:"},{"location":"InDetailDefFile/#2-post-section","text":"This section runs a series of commands to set up the environment inside the container. Everything in the %post section is executed after the base image is pulled. %post a) System Update and Install Dependencies: apt-get update && apt-get install -y \\ wget \\ curl \\ build-essential \\ libssl-dev \\ libcurl4-openssl-dev \\ libxml2-dev \\ software-properties-common \\ dirmngr \\ gnupg2 \\ locales apt-get update: Updates the package list for the Ubuntu system so that the latest versions of software can be installed. apt-get install: Installs the specified packages. wget and curl: Tools to download files and data over HTTP/FTP. build-essential: A meta-package that installs essential tools for compiling and building software (like gcc, make). libssl-dev, libcurl4-openssl-dev, libxml2-dev: Development libraries often required for installing Python/R packages (particularly those that involve networking, encryption, or XML parsing). software-properties-common: Enables the management of software repositories. dirmngr, gnupg2: Tools needed to manage and work with GPG keys (used to sign and verify software sources). locales: Allows the configuration of system language settings. b) Set Locale: locale-gen en_US.UTF-8 update-locale LANG=en_US.UTF-8 locale-gen en_US.UTF-8: Generates the en_US.UTF-8 locale, which is a widely used UTF-8 encoded character set. It ensures that the environment supports a full range of characters, which is important for Python, R, and JupyterLab. update-locale: Applies the locale changes by setting the LANG environment variable. c) Install Python, Pip, and JupyterLab: apt-get install -y python3 python3-pip python3-dev pip3 install --upgrade pip pip3 install jupyterlab apt-get install python3, python3-pip, python3-dev: Installs Python 3 and its development tools (python3-dev), which are required for building Python modules and extensions. pip3 install --upgrade pip: Upgrades pip (Python's package manager) to the latest version to ensure that newer Python packages can be installed. pip3 install jupyterlab: Installs JupyterLab, a web-based interactive development environment for notebooks, code, and data. d) Install R and R Development Tools: apt-get install -y r-base r-base-dev These are all ubuntu system packages - if you want another version of R you need to change this. r-base: Installs the core R environment. r-base-dev: Includes additional tools needed to compile R packages from source. e) Install R-Jupyter Integration (IRKernel): R -e \"install.packages('IRkernel', repos='https://cloud.r-project.org","title":"2. %post Section:"},{"location":"InDetailDefFile/#2-environment-section","text":"# Set environment variables export LC_ALL=C.UTF-8 export LANG=C.UTF-8 export PYTHONNOUSERSITE=\"true\" This part is one of the benefits of using ChatGPT - in all my definition files before that I have not set these variables and was rewarded by warnings messages at every step. LC_ALL and LANG : Setting these environment variables ensures that the container's environment adheres to the specified locale settings when it's running. PYTHONNOUSERSITE=\"true\" : This env variable forces Python to install packages in the system's library path and not your personly Python library.","title":"2. %environment Section:"},{"location":"InDetailDefFile/#3-runscript","text":"jupyter lab --no-browser --ip=0.0.0.0 --allow-root This will start the jupyter web browser and write the connection details into the stdout of the slurm job.","title":"3. %runscript"},{"location":"InDetailDefFile/#4-labels-section-and-5-help-section","text":"Both of these sections are not necessary for the image to build, but would help us a lot if you would still maintain them! The %labels section can be queried like that: apptainer inspect <your_image>.sif and the %help section like that: apptainer run <our_image>.sif You can see how a well maintained apptainer image can help both you and also us later on - not claiming that I have maintained my images well...","title":"4. %labels Section and 5. %help Section"}]}